{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10523,
     "status": "ok",
     "timestamp": 1614624209059,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "xdEXmdzP7kWN",
    "outputId": "52f31504-19a9-4897-d4b5-39b27b3efaab"
   },
   "source": [
    "# *INSERT TUTORIAL PIC HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the seventh MAST-ML tutorial notebook, \n",
    "\n",
    "# Model Base Line Tests with MAST-ML! \n",
    "\n",
    "## In this notebook, we will learn how to run some baseline tests on our models. In this tutorial, we will:\n",
    "\n",
    "1. [Set up MAST-ML on Colab and begin session](#task1)\n",
    "2. [Import Dataset](#task2)\n",
    "3. [Run Base line tests on our model](#task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XjqmeWKD_8V"
   },
   "source": [
    "## Task 1: Set up MAST-ML on Colab and begin session <a name=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL-8py9CD_8V"
   },
   "source": [
    "If you are working on Google Colab and need to install MAST-ML, \n",
    "begin by pip installing MAST-ML to the Colab session\n",
    "and install the needed dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 63854,
     "status": "ok",
     "timestamp": 1618264341401,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 300
    },
    "id": "0vL8nZnnD_8W",
    "outputId": "3bf49e89-96b8-4cbb-f30b-430ff85295be"
   },
   "outputs": [],
   "source": [
    "!pip install mastml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2UQ0X4yD_8W"
   },
   "source": [
    "Sync your Google drive to Colab so that we can save MAST-ML results to our Google\n",
    "Drive. If we save to the Colab session, the data will be deleted when the session \n",
    "ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24972,
     "status": "ok",
     "timestamp": 1618264379202,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 300
    },
    "id": "w-jHgEAFquSh",
    "outputId": "95cc2f0e-c93b-4732-bafb-4369e0429488"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the MAST-ML folder to our sys path so that python can find the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1614624313213,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "nwQO48j1ws3S"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('MAST-ML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the MAST-ML modules used in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1614624316133,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "x8GIei1qQoWL",
    "outputId": "6480ed4e-44d3-43c9-f5c3-1fb1c1063801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figshare is an optional dependency. To import data from figshare, manually install figshare via git clone of git clone https://github.com/cognoma/figshare.git\n",
      "XGBoost is an optional dependency. If you want to use XGBoost models, please manually install xgboost package with pip install xgboost. If have error with finding libxgboost.dylib library, dobrew install libomp. If do not have brew on your system, first do ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" from the Terminal\n",
      "forestci is an optional dependency. To install latest forestci compatabilty with scikit-learn>=0.24, run pip install git+git://github.com/scikit-learn-contrib/forest-confidence-interval.git\n"
     ]
    }
   ],
   "source": [
    "import mastml\n",
    "from mastml.datasets import LocalDatasets\n",
    "from mastml.models import SklearnModel, EnsembleModel\n",
    "from mastml.preprocessing import SklearnPreprocessor\n",
    "from mastml.metrics import Metrics\n",
    "from mastml.baseline_tests import Baseline_tests\n",
    "from mastml.datasets import SklearnDatasets\n",
    "\n",
    "import os\n",
    "data_path = os.path.join(mastml.__path__[0], 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Import dataset <a name=\"task2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will again use the diffusion dataset that we examined in the previous tutorial. Here, we use the LocalDatasets module to load in the diffusion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: feature_names not specified but target was specified. Assuming all columns except target and extra columns are features\n"
     ]
    }
   ],
   "source": [
    "target = 'E_regression'\n",
    "\n",
    "extra_columns = ['Material compositions 1', 'Material compositions 2']\n",
    "\n",
    "d = LocalDatasets(file_path=data_path+'\\\\diffusion_data_selectfeatures.xlsx', \n",
    "                  target=target, \n",
    "                  extra_columns=extra_columns, \n",
    "                  group_column='Material compositions 1',\n",
    "                  testdata_columns=None,\n",
    "                  as_frame=True)\n",
    "\n",
    "# Load the data with the load_data() method\n",
    "data_dict = d.load_data()\n",
    "\n",
    "# Let's assign each data object to its respective name\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "X_extra = data_dict['X_extra']\n",
    "groups = data_dict['groups']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this tutorial, we will be using RandomForestRegressor as our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SklearnModel(model='RandomForestRegressor', n_estimators=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:  Run baseline tests on regression model <a name=\"task3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list which metrics we want to evaluate. If none are given, MAST-ML will default to evaulating just the root mean squared error. A complete list of metrics can be obtained from calling Metrics()._metric_zoo() in metrics.py.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous tutorial, we need to define our preprocessing function. We are just going to use the basic StandardScaler in scikit-learn to normalize each column to have mean zero and standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site2_MeltingT</th>\n",
       "      <th>BCCenergy_pa_max_value</th>\n",
       "      <th>BCCefflatcnt_difference</th>\n",
       "      <th>Site1_BCCefflatcnt</th>\n",
       "      <th>Site1_CovalentRadius</th>\n",
       "      <th>NdUnfilled_max_value</th>\n",
       "      <th>n_ws^third_max_value</th>\n",
       "      <th>Site2_Row</th>\n",
       "      <th>Site2_NdUnfilled</th>\n",
       "      <th>MendeleevNumber_composition_average</th>\n",
       "      <th>Site2_MendeleevNumber</th>\n",
       "      <th>Site2_IonizationEnergy</th>\n",
       "      <th>Site1_GSestFCClatcnt</th>\n",
       "      <th>IonicRadii_composition_average</th>\n",
       "      <th>HeatVaporization_min_value</th>\n",
       "      <th>HHIr_difference</th>\n",
       "      <th>Site2_ICSDVolume</th>\n",
       "      <th>NdUnfilled_composition_average</th>\n",
       "      <th>Polarizability_max_value</th>\n",
       "      <th>Site2_BCCvolume_padiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.531814</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>-1.254233</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.412734</td>\n",
       "      <td>-1.388936</td>\n",
       "      <td>-1.573418</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>-0.943565</td>\n",
       "      <td>0.587584</td>\n",
       "      <td>0.446102</td>\n",
       "      <td>-0.017709</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>3.133860</td>\n",
       "      <td>-0.156934</td>\n",
       "      <td>-1.099257</td>\n",
       "      <td>-0.312672</td>\n",
       "      <td>-1.260505</td>\n",
       "      <td>-0.891095</td>\n",
       "      <td>0.279416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064051</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>0.204143</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.412734</td>\n",
       "      <td>-0.369717</td>\n",
       "      <td>0.477555</td>\n",
       "      <td>-0.855029</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>0.265113</td>\n",
       "      <td>0.081144</td>\n",
       "      <td>0.224198</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>1.357710</td>\n",
       "      <td>-0.156934</td>\n",
       "      <td>-0.580394</td>\n",
       "      <td>-1.040516</td>\n",
       "      <td>-0.495578</td>\n",
       "      <td>-0.802413</td>\n",
       "      <td>0.442443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524584</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>-0.006534</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.412734</td>\n",
       "      <td>0.309763</td>\n",
       "      <td>0.372377</td>\n",
       "      <td>-0.855029</td>\n",
       "      <td>0.613776</td>\n",
       "      <td>-0.149493</td>\n",
       "      <td>-0.388087</td>\n",
       "      <td>-0.718343</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>1.251141</td>\n",
       "      <td>-0.156934</td>\n",
       "      <td>-0.021619</td>\n",
       "      <td>-0.929489</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>-0.089477</td>\n",
       "      <td>0.334594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.394504</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.412734</td>\n",
       "      <td>-1.388936</td>\n",
       "      <td>-0.994938</td>\n",
       "      <td>-0.855029</td>\n",
       "      <td>-0.943565</td>\n",
       "      <td>0.541517</td>\n",
       "      <td>0.393965</td>\n",
       "      <td>0.111308</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>1.641894</td>\n",
       "      <td>-0.156934</td>\n",
       "      <td>-1.059344</td>\n",
       "      <td>-0.954162</td>\n",
       "      <td>-1.260505</td>\n",
       "      <td>-0.891095</td>\n",
       "      <td>0.349643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112116</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>0.147244</td>\n",
       "      <td>0.412734</td>\n",
       "      <td>-0.029977</td>\n",
       "      <td>0.582733</td>\n",
       "      <td>-0.855029</td>\n",
       "      <td>0.302307</td>\n",
       "      <td>0.126911</td>\n",
       "      <td>-0.075266</td>\n",
       "      <td>0.235845</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>1.002480</td>\n",
       "      <td>-0.156934</td>\n",
       "      <td>-1.099257</td>\n",
       "      <td>-0.966498</td>\n",
       "      <td>-0.240602</td>\n",
       "      <td>-0.645915</td>\n",
       "      <td>0.344627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.161729</td>\n",
       "      <td>-0.781716</td>\n",
       "      <td>-0.390855</td>\n",
       "      <td>1.377227</td>\n",
       "      <td>2.514173</td>\n",
       "      <td>1.328982</td>\n",
       "      <td>-0.100925</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.925244</td>\n",
       "      <td>-1.209041</td>\n",
       "      <td>-0.492361</td>\n",
       "      <td>-0.617997</td>\n",
       "      <td>1.447955</td>\n",
       "      <td>0.220974</td>\n",
       "      <td>2.400344</td>\n",
       "      <td>1.375318</td>\n",
       "      <td>-0.176972</td>\n",
       "      <td>2.309155</td>\n",
       "      <td>1.006009</td>\n",
       "      <td>0.344627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1.765340</td>\n",
       "      <td>-0.781716</td>\n",
       "      <td>-0.378603</td>\n",
       "      <td>1.377227</td>\n",
       "      <td>2.514173</td>\n",
       "      <td>1.328982</td>\n",
       "      <td>-0.153514</td>\n",
       "      <td>1.291752</td>\n",
       "      <td>1.236712</td>\n",
       "      <td>-1.162974</td>\n",
       "      <td>-0.440224</td>\n",
       "      <td>0.251076</td>\n",
       "      <td>1.447955</td>\n",
       "      <td>0.220974</td>\n",
       "      <td>2.400344</td>\n",
       "      <td>-0.221182</td>\n",
       "      <td>-0.238654</td>\n",
       "      <td>2.564131</td>\n",
       "      <td>1.006009</td>\n",
       "      <td>0.344627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.257430</td>\n",
       "      <td>-0.781716</td>\n",
       "      <td>-0.110537</td>\n",
       "      <td>1.377227</td>\n",
       "      <td>2.514173</td>\n",
       "      <td>1.328982</td>\n",
       "      <td>-0.731993</td>\n",
       "      <td>-0.855029</td>\n",
       "      <td>1.548180</td>\n",
       "      <td>-1.393311</td>\n",
       "      <td>-0.700908</td>\n",
       "      <td>-0.671754</td>\n",
       "      <td>1.447955</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>1.156580</td>\n",
       "      <td>-0.700132</td>\n",
       "      <td>-0.238654</td>\n",
       "      <td>2.819107</td>\n",
       "      <td>1.006009</td>\n",
       "      <td>0.419870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.888986</td>\n",
       "      <td>-0.781716</td>\n",
       "      <td>-1.097630</td>\n",
       "      <td>1.377227</td>\n",
       "      <td>2.514173</td>\n",
       "      <td>1.328982</td>\n",
       "      <td>-1.100116</td>\n",
       "      <td>1.291752</td>\n",
       "      <td>1.548180</td>\n",
       "      <td>-1.301176</td>\n",
       "      <td>-0.596634</td>\n",
       "      <td>-0.815106</td>\n",
       "      <td>1.447955</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>2.400344</td>\n",
       "      <td>-1.099257</td>\n",
       "      <td>0.353491</td>\n",
       "      <td>2.819107</td>\n",
       "      <td>1.006009</td>\n",
       "      <td>0.179091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-1.347640</td>\n",
       "      <td>-0.781716</td>\n",
       "      <td>-0.833573</td>\n",
       "      <td>1.377227</td>\n",
       "      <td>2.514173</td>\n",
       "      <td>1.328982</td>\n",
       "      <td>-1.310473</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>-0.943565</td>\n",
       "      <td>0.311180</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>-0.218402</td>\n",
       "      <td>1.447955</td>\n",
       "      <td>0.469635</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>-0.700132</td>\n",
       "      <td>0.920963</td>\n",
       "      <td>0.779301</td>\n",
       "      <td>1.006009</td>\n",
       "      <td>-3.695946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Site2_MeltingT  BCCenergy_pa_max_value  BCCefflatcnt_difference  \\\n",
       "0         -0.531814                0.931053                -1.254233   \n",
       "1          0.064051                0.931053                 0.204143   \n",
       "2          0.524584                0.931053                -0.006534   \n",
       "3         -0.394504                0.931053                 0.018934   \n",
       "4          0.112116                0.931053                 0.119309   \n",
       "..              ...                     ...                      ...   \n",
       "403        1.161729               -0.781716                -0.390855   \n",
       "404        1.765340               -0.781716                -0.378603   \n",
       "405        0.257430               -0.781716                -0.110537   \n",
       "406        0.888986               -0.781716                -1.097630   \n",
       "407       -1.347640               -0.781716                -0.833573   \n",
       "\n",
       "     Site1_BCCefflatcnt  Site1_CovalentRadius  NdUnfilled_max_value  \\\n",
       "0              0.147244              0.412734             -1.388936   \n",
       "1              0.147244              0.412734             -0.369717   \n",
       "2              0.147244              0.412734              0.309763   \n",
       "3              0.147244              0.412734             -1.388936   \n",
       "4              0.147244              0.412734             -0.029977   \n",
       "..                  ...                   ...                   ...   \n",
       "403            1.377227              2.514173              1.328982   \n",
       "404            1.377227              2.514173              1.328982   \n",
       "405            1.377227              2.514173              1.328982   \n",
       "406            1.377227              2.514173              1.328982   \n",
       "407            1.377227              2.514173              1.328982   \n",
       "\n",
       "     n_ws^third_max_value  Site2_Row  Site2_NdUnfilled  \\\n",
       "0               -1.573418   0.218361         -0.943565   \n",
       "1                0.477555  -0.855029         -0.009161   \n",
       "2                0.372377  -0.855029          0.613776   \n",
       "3               -0.994938  -0.855029         -0.943565   \n",
       "4                0.582733  -0.855029          0.302307   \n",
       "..                    ...        ...               ...   \n",
       "403             -0.100925   0.218361          0.925244   \n",
       "404             -0.153514   1.291752          1.236712   \n",
       "405             -0.731993  -0.855029          1.548180   \n",
       "406             -1.100116   1.291752          1.548180   \n",
       "407             -1.310473   0.218361         -0.943565   \n",
       "\n",
       "     MendeleevNumber_composition_average  Site2_MendeleevNumber  \\\n",
       "0                               0.587584               0.446102   \n",
       "1                               0.265113               0.081144   \n",
       "2                              -0.149493              -0.388087   \n",
       "3                               0.541517               0.393965   \n",
       "4                               0.126911              -0.075266   \n",
       "..                                   ...                    ...   \n",
       "403                            -1.209041              -0.492361   \n",
       "404                            -1.162974              -0.440224   \n",
       "405                            -1.393311              -0.700908   \n",
       "406                            -1.301176              -0.596634   \n",
       "407                             0.311180               1.228154   \n",
       "\n",
       "     Site2_IonizationEnergy  Site1_GSestFCClatcnt  \\\n",
       "0                 -0.017709              0.183395   \n",
       "1                  0.224198              0.183395   \n",
       "2                 -0.718343              0.183395   \n",
       "3                  0.111308              0.183395   \n",
       "4                  0.235845              0.183395   \n",
       "..                      ...                   ...   \n",
       "403               -0.617997              1.447955   \n",
       "404                0.251076              1.447955   \n",
       "405               -0.671754              1.447955   \n",
       "406               -0.815106              1.447955   \n",
       "407               -0.218402              1.447955   \n",
       "\n",
       "     IonicRadii_composition_average  HeatVaporization_min_value  \\\n",
       "0                          3.133860                   -0.156934   \n",
       "1                          1.357710                   -0.156934   \n",
       "2                          1.251141                   -0.156934   \n",
       "3                          1.641894                   -0.156934   \n",
       "4                          1.002480                   -0.156934   \n",
       "..                              ...                         ...   \n",
       "403                        0.220974                    2.400344   \n",
       "404                        0.220974                    2.400344   \n",
       "405                        0.114405                    1.156580   \n",
       "406                        0.895911                    2.400344   \n",
       "407                        0.469635                    0.142081   \n",
       "\n",
       "     HHIr_difference  Site2_ICSDVolume  NdUnfilled_composition_average  \\\n",
       "0          -1.099257         -0.312672                       -1.260505   \n",
       "1          -0.580394         -1.040516                       -0.495578   \n",
       "2          -0.021619         -0.929489                        0.014374   \n",
       "3          -1.059344         -0.954162                       -1.260505   \n",
       "4          -1.099257         -0.966498                       -0.240602   \n",
       "..               ...               ...                             ...   \n",
       "403         1.375318         -0.176972                        2.309155   \n",
       "404        -0.221182         -0.238654                        2.564131   \n",
       "405        -0.700132         -0.238654                        2.819107   \n",
       "406        -1.099257          0.353491                        2.819107   \n",
       "407        -0.700132          0.920963                        0.779301   \n",
       "\n",
       "     Polarizability_max_value  Site2_BCCvolume_padiff  \n",
       "0                   -0.891095                0.279416  \n",
       "1                   -0.802413                0.442443  \n",
       "2                   -0.089477                0.334594  \n",
       "3                   -0.891095                0.349643  \n",
       "4                   -0.645915                0.344627  \n",
       "..                        ...                     ...  \n",
       "403                  1.006009                0.344627  \n",
       "404                  1.006009                0.344627  \n",
       "405                  1.006009                0.419870  \n",
       "406                  1.006009                0.179091  \n",
       "407                  1.006009               -3.695946  \n",
       "\n",
       "[408 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "preprocessor.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline_test takes in the argument X, y, model, and the metrics used to evaluate the model. Here we will go through on how to use the mean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test = Baseline_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_mean will print out the score of the model tested with the actual y compared with the naive score of the model tested with the mean value of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 0.9801730039276285\n",
      "Fake: 0.0 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.044772539510946556\n",
      "Fake: 0.2928962336751531 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.06165474483807767\n",
      "Fake: 0.4116233755078354 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.14080836648570116\n",
      "Fake: 8474454311104335.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_mean(X=X, y=y, model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_permuted will print out the score of the model tested with the actual y compared with the naive score of the model tested with the y shuffled so that it does not correspond to the X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 0.981176616917211\n",
      "Fake: -0.3592175181662185 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.04454091088024687\n",
      "Fake: 0.4271994443895473 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.06312124659586443\n",
      "Fake: 0.5363783111006497 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.1371983348397093\n",
      "Fake: 1.1658548443808168 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_permuted(X=X, y=y, model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_nearest_neighbour_kdTree will print out the score of the model tested with the actual y compared with the naive score of the model tested with the nearest neighbour datapoint's y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 0.9889714832583125\n",
      "Fake: 0.7395269289526998 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.03625086717152263\n",
      "Fake: 0.17155767158419746 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.05251680292165585\n",
      "Fake: 0.2513253138804576 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.10501674505376488\n",
      "Fake: 0    0.510366\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_nearest_neighbour_kdtree(X=X, y=y, model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_nearest_neighbour_cdist will print out the score of the model tested with the actual y compared with the naive score of the model tested with the nearest neighbour datapoint's y. This method can take an extra argument d_metric as a metric to calculate the distance such as:\n",
    "\n",
    "‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’, ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulsinski’, ‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘wminkowski’, ‘yule’\n",
    "\n",
    "default is euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 0.9876693504931018\n",
      "Fake: 0.8581094999629117 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.04001719000921805\n",
      "Fake: 0.15284566649432096 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.05688773473048952\n",
      "Fake: 0.1997243302544913 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.11104345774019408\n",
      "Fake: 0.37668355424293254 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_nearest_neighbour_cdist(X=X, y=y, model=model, metrics=metrics, d_metric =\"cityblock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:  Run baseline tests on classifier model <a name=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classifier base line tests, lets use KNeighborsClassifier as our model and iris as our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = SklearnDatasets(as_frame=True).load_iris()\n",
    "model = SklearnModel(model=\"KNeighborsClassifier\")\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_classifier_dominant compares the score of the model with a test value of the dominant class (ie, the class with the highest count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 1.0\n",
      "Fake: 0.0 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.0\n",
      "Fake: 12.066666666666666 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.0\n",
      "Fake: 12.094075684675811 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.0\n",
      "Fake: inf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_classifier_dominant(X, y, model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_classifier_dominant compares the score of the model with a test value of a random class. In this iris dataset, it will randomly guess class 0, 1, or 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score score:\n",
      "Real: 0.8821218074656189\n",
      "Fake: 0.0 \n",
      "\n",
      "mean_absolute_error score:\n",
      "Real: 0.06666666666666667\n",
      "Fake: 0.6333333333333333 \n",
      "\n",
      "root_mean_squared_error score:\n",
      "Real: 0.2581988897471611\n",
      "Fake: 0.7958224257542215 \n",
      "\n",
      "rmse_over_stdev score:\n",
      "Real: 0.34333393734727286\n",
      "Fake: inf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_test.test_classifier_random(X, y, model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of the examples, the actual score of the models performed significantly better compared to the scores tested with a fake test. Therefore, we know that our models have some reliability and are not completely useless. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
