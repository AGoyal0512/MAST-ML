{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10523,
     "status": "ok",
     "timestamp": 1614624209059,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "xdEXmdzP7kWN",
    "outputId": "52f31504-19a9-4897-d4b5-39b27b3efaab"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################################\n",
    "#\n",
    "#  Welcome to the sixth MAST-ML tutorial notebook, MASTML_Tutorial_6_ErrorAnalysis_UncertaintyQuantification.ipynb! \n",
    "#  In this notebook tutorial, we will learn about how MAST-ML can be used to: \n",
    "#       1. Assess the true and predicted errors of our model, and some useful measures of their statistical distributions\n",
    "#       2. Explore different methods of quantifying and calibrating model uncertainties. \n",
    "#       3. Compare the uncertainty quantification behavior of Bayesian and ensemble-based models.\n",
    "#\n",
    "########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#\n",
    "# Task 0: Setting up MAST-ML in Colab\n",
    "#\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are working on Google Colab and need to install MAST-ML, \n",
    "# begin by cloning the relevant branch of MAST-ML to the Colab session\n",
    "# and install the needed dependencies:\n",
    "\n",
    "!git clone --single-branch --branch dev_Ryan_2020-12-21 https://github.com/uw-cmg/MAST-ML\n",
    "!pip install -r MAST-ML/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23965,
     "status": "ok",
     "timestamp": 1614624307314,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "w-jHgEAFquSh",
    "outputId": "3a745bff-5d3b-4f64-df23-7095a8d0c670"
   },
   "outputs": [],
   "source": [
    "# Sync your Google drive to Colab so that we can save MAST-ML results to our Google\n",
    "# Drive. If we save to the Colab session, the data will be deleted when the session \n",
    "# ends.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1614624313213,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "nwQO48j1ws3S"
   },
   "outputs": [],
   "source": [
    "# We need to add the MAST-ML folder to our sys path so that python can find the modules\n",
    "import sys\n",
    "sys.path.append('MAST-ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1614624316133,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "x8GIei1qQoWL",
    "outputId": "6480ed4e-44d3-43c9-f5c3-1fb1c1063801"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Here we import the MAST-ML modules used in this tutorial\n",
    "from mastml.mastml import Mastml\n",
    "from mastml.datasets import LocalDatasets\n",
    "from mastml.preprocessing import SklearnPreprocessor\n",
    "from mastml.models import SklearnModel\n",
    "from mastml.data_splitters import SklearnDataSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1614624317207,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "Xf8MFHjlM7Oe",
    "outputId": "71bbe4eb-544e-40de-ef0d-b57e8f632841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/MyDrive/MASTML_results_GettingStarted_1 not empty. Renaming...\n"
     ]
    }
   ],
   "source": [
    "# Set the name of the savepath to save MAST-ML results to\n",
    "SAVEPATH = 'drive/MyDrive/MASTML_tutorial_6_ErrorAnalysis_UncertaintyQuantification'\n",
    "\n",
    "# Initialize the MAST-ML run, write savepath\n",
    "mastml = Mastml(savepath=SAVEPATH)\n",
    "savepath = mastml.get_savepath\n",
    "\n",
    "# When the above command is run, a new folder with the name designated SAVEPATH is created.\n",
    "# This is where all of the output for the current MAST-ML run will be saved to.\n",
    "# Note that you can perform multiple runs with the same folder name, and the current datetime\n",
    "# will be appended to the name so that no data is lost or overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "#\n",
    "# Task 1: Assess the true and predicted errors of our model, and some useful measures \n",
    "#         of their statistical distributions\n",
    "#\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutorial, we will again use the diffusion dataset that we examined in the \n",
    "# previous tutorial. Here, we use the LocalDatasets module to load in the diffusion dataset. \n",
    "\n",
    "# Need to denote the column name of the target (y-data)\n",
    "target = 'E_regression'\n",
    "\n",
    "# There are columns in the data file not used as features or target. We need to\n",
    "# list them here in the parameter extra_columns\n",
    "extra_columns = ['Material compositions 1', 'Material compositions 2']\n",
    "\n",
    "# Here, we make an instance of our LocalDatasets class. It needs a few parameters:\n",
    "#   file_path: where the data is stored\n",
    "#   target: the column name of the y-data\n",
    "#   extra_columns: list containing extra columns in the data file not used for fitting\n",
    "#   group_column: column name denoting group labels (only used for LeaveOutGroup CV)\n",
    "#   testdata_columns: column names denoting left-out data to evaluate using best\n",
    "#     model from CV tests. This is manual way to leave out data. Can also be done\n",
    "#     automatically using nested CV (we will do this in later tutorials)\n",
    "#   as_frame: whether to return data as dataframe. Want this to be true.\n",
    "d = LocalDatasets(file_path='../mastml/data/diffusion_data_selectfeatures.xlsx', #'MAST-ML/mastml/data/figshare_7418492/All_Model_Data.xlsx'\n",
    "                  target=target, \n",
    "                  extra_columns=extra_columns, \n",
    "                  group_column='Material compositions 1',\n",
    "                  testdata_columns=None,\n",
    "                  as_frame=True)\n",
    "\n",
    "# Load the data with the load_data() method\n",
    "data_dict = d.load_data()\n",
    "\n",
    "# Let's assign each data object to its respective name\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "X_extra = data_dict['X_extra']\n",
    "groups = data_dict['groups']\n",
    "X_testdata = data_dict['X_testdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "model_rf = SklearnModel(model='RandomForestRegressor', n_estimators=150)\n",
    "model_ens = EnsembleModel(model='Ridge', n_estimators=150)\n",
    "models = [model_rf, model_ens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "model_rf = SklearnModel(model='RandomForestRegressor', n_estimators=150)\n",
    "splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=1, n_splits=5)\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  models=[model_rf],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Error'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  nested_CV=True,\n",
    "                  error_method='stdev_weak_learners', \n",
    "                  recalibrate_errors=True,\n",
    "                  verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "#\n",
    "# Task 2: Explore different methods of quantifying and calibrating model uncertainties. \n",
    "#\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "model_rf = SklearnModel(model='RandomForestRegressor', n_estimators=150)\n",
    "splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=1, n_splits=5)\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  models=[model_rf],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Error'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  nested_CV=True,\n",
    "                  error_method='jackknife_after_bootstrap', \n",
    "                  recalibrate_errors=True,\n",
    "                  verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "#\n",
    "# Task 3: Compare the uncertainty quantification behavior of Bayesian and ensemble-based models.\n",
    "#\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "model_rf = SklearnModel(model='RandomForestRegressor', n_estimators=150)\n",
    "model_ens = EnsembleModel(model='Ridge', n_estimators=150)\n",
    "model_gpr = SklearnModel(model='GaussianProcessRegressor', kernel='ConstantKernel*RBF', n_restarts_optimizer=10)\n",
    "\n",
    "models = [model_rf, model_ens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've now completed your sixth MAST-ML tutorial notebook! You have almost reached the end of the MAST-ML\n",
    "# tutorial series. The final tutorial in this series details how to upload your best trained models to \n",
    "# the DLHub database for other people to use, and use these shared models to make predictions on new data\n",
    "# with only a few lines of python code.\n",
    "#\n",
    "# The next example in this notebook series is titled MASTML_Tutorial_7_ModelHosting_and_Predictions.ipynb, \n",
    "# and will guide you through the process of sharing your favorite models on the DLHub model hosting service,\n",
    "# then use this newly hosted model to make predictions on new data."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMEVkHt3gXnG4BXBNcr+orE",
   "name": "MASTML_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
