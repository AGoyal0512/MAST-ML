{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10523,
     "status": "ok",
     "timestamp": 1614624209059,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "xdEXmdzP7kWN",
    "outputId": "52f31504-19a9-4897-d4b5-39b27b3efaab"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#\n",
    "#  Welcome to the fifth MAST-ML tutorial notebook, MASTML_Tutorial_5_NestedCV_and_OptimizedModels.ipynb! \n",
    "#  In this notebook, we will perform more advanced model fitting routines, including nested cross validation\n",
    "#  and hyperparameter optimization. In this tutorial, we will learn how to use MAST-ML to:\n",
    "#       1. Assess performance on manually left-out test data\n",
    "#       2. Perform nested cross validation to assess model performance on unseen data\n",
    "#       3. Optimize the hyperparameters of our models to create the best model\n",
    "#\n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#\n",
    "# Task 0: Setting up MAST-ML in Colab\n",
    "#\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are working on Google Colab and need to install MAST-ML, \n",
    "# begin by cloning the relevant branch of MAST-ML to the Colab session\n",
    "# and install the needed dependencies:\n",
    "\n",
    "!git clone --single-branch --branch dev_Ryan_2020-12-21 https://github.com/uw-cmg/MAST-ML\n",
    "!pip install -r MAST-ML/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23965,
     "status": "ok",
     "timestamp": 1614624307314,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "w-jHgEAFquSh",
    "outputId": "3a745bff-5d3b-4f64-df23-7095a8d0c670"
   },
   "outputs": [],
   "source": [
    "# Sync your Google drive to Colab so that we can save MAST-ML results to our Google\n",
    "# Drive. If we save to the Colab session, the data will be deleted when the session \n",
    "# ends.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1614624313213,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "nwQO48j1ws3S"
   },
   "outputs": [],
   "source": [
    "# We need to add the MAST-ML folder to our sys path so that python can find the modules\n",
    "import sys\n",
    "sys.path.append('MAST-ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1614624316133,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "x8GIei1qQoWL",
    "outputId": "6480ed4e-44d3-43c9-f5c3-1fb1c1063801"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Here we import the MAST-ML modules used in this tutorial\n",
    "from mastml.mastml import Mastml\n",
    "from mastml.datasets import LocalDatasets\n",
    "from mastml.models import SklearnModel\n",
    "from mastml.preprocessing import SklearnPreprocessor\n",
    "from mastml.data_splitters import SklearnDataSplitter, NoSplit\n",
    "from mastml.hyper_opt import GridSearch, RandomizedSearch, BayesianSearch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1614624317207,
     "user": {
      "displayName": "Ryan Jacobs",
      "photoUrl": "",
      "userId": "08020825119070462259"
     },
     "user_tz": 360
    },
    "id": "Xf8MFHjlM7Oe",
    "outputId": "71bbe4eb-544e-40de-ef0d-b57e8f632841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/MyDrive/MASTML_tutorial_5_NestedCV_and_OptimizedModels not empty. Renaming...\n"
     ]
    }
   ],
   "source": [
    "# Set the name of the savepath to save MAST-ML results to\n",
    "SAVEPATH = 'drive/MyDrive/MASTML_tutorial_5_NestedCV_and_OptimizedModels'\n",
    "\n",
    "# Initialize the MAST-ML run, write savepath\n",
    "mastml = Mastml(savepath=SAVEPATH)\n",
    "savepath = mastml.get_savepath\n",
    "\n",
    "# When the above command is run, a new folder with the name designated SAVEPATH is created.\n",
    "# This is where all of the output for the current MAST-ML run will be saved to.\n",
    "# Note that you can perform multiple runs with the same folder name, and the current datetime\n",
    "# will be appended to the name so that no data is lost or overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "# Task 1: Assess performance on manually left-out test data\n",
    "#\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutorial, we will see there are two ways to evaluate models in\n",
    "# a \"two-level\" fashion, i.e. where we split data into train/leftout data, \n",
    "# then build and evaluate models with a cross validation data splitter on\n",
    "# the training set to build various sub train/test splits. This is also\n",
    "# commonly called nested cross validation. The leftout data is never used \n",
    "# in training at any point, so can function as a good approximation for\n",
    "# how the model may perform on new, unseen data.\n",
    "#\n",
    "# MAST-ML offers two methods to do this. The first is for the user to specify \n",
    "# specific data points in the imported data that should be reserved as left-out\n",
    "# data. The second method is to perform an automatic nested cross-validation scheme.\n",
    "# Here, we will showcase the first method where some data points are manually\n",
    "# selected to function as left-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: feature_names not specified but target was specified. Assuming all columns except target and extra columns are features\n"
     ]
    }
   ],
   "source": [
    "# In this tutorial, we will again use the diffusion dataset that we examined in the \n",
    "# previous tutorials. Here, we use the LocalDatasets module to load in the diffusion dataset. \n",
    "# We are using the diffusion_data_leaveoutPt.xlsx file as it contains a column denoting\n",
    "# the data to leave out (those with Pt as the host element)\n",
    "\n",
    "# To specify which data points are left out, we made a new column in the data file (it can\n",
    "# have whatever name you want), and then label 0 if the data is not left out data and 1\n",
    "# if the data is to be used as left-out data. For this example we are using all data where\n",
    "# Pt is the host element as left out data.\n",
    "\n",
    "# Need to denote the column name of the target (y-data)\n",
    "target = 'E_regression'\n",
    "\n",
    "# There are columns in the data file not used as features or target. We need to\n",
    "# list them here in the parameter extra_columns\n",
    "extra_columns = ['Material compositions 1', 'Material compositions 2', 'is_testdata']\n",
    "\n",
    "# Here, we make an instance of our LocalDatasets class. It needs a few parameters:\n",
    "#   file_path: where the data is stored\n",
    "#   target: the column name of the y-data\n",
    "#   extra_columns: list containing extra columns in the data file not used for fitting\n",
    "#   group_column: column name denoting group labels (only used for LeaveOutGroup CV)\n",
    "#   testdata_columns: column names denoting left-out data to evaluate using best\n",
    "#     model from CV tests. This is manual way to leave out data. In our current case, \n",
    "#     the column called \"is_testdata\" denotes which points will be left out\n",
    "#   as_frame: whether to return data as dataframe. Want this to be true.\n",
    "d = LocalDatasets(file_path='../mastml/data/diffusion_data_leaveoutPt.xlsx', #'MAST-ML/mastml/data/figshare_7418492/All_Model_Data.xlsx'\n",
    "                  target=target, \n",
    "                  extra_columns=extra_columns, \n",
    "                  group_column='Material compositions 1',\n",
    "                  testdata_columns=['is_testdata'],\n",
    "                  as_frame=True)\n",
    "\n",
    "# Load the data with the load_data() method\n",
    "data_dict = d.load_data()\n",
    "\n",
    "# Let's assign each data object to its respective name\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "X_extra = data_dict['X_extra']\n",
    "groups = data_dict['groups']\n",
    "X_testdata = data_dict['X_testdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have one left out data set in this example, so X_testdata is a list with an array containing\n",
    "# the indices of the left out data, which will be automatically used in our data splitter. We\n",
    "# see there are 30 left out data points, which correspond to the number of points where Pt is the\n",
    "# host element\n",
    "X_testdata[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to primarily be evaluating Kernel ridge models in this tutorial. Let's build \n",
    "# and run a Kernel ridge model using random 5-fold cross validation, where we also specify\n",
    "# our X_testdata in the splitter evaluate() method (as the leaveout_inds parameter),\n",
    "# so that it knows to predict the values of the left out data.\n",
    "\n",
    "model_krr = SklearnModel(model='KernelRidge', kernel='rbf')\n",
    "preprocessor = SklearnPreprocessor(preprocessor='StandardScaler', as_frame=True)\n",
    "metrics = ['r2_score', 'mean_absolute_error', 'root_mean_squared_error', 'rmse_over_stdev']\n",
    "splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=1, n_splits=5)\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  models=[model_krr],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  leaveout_inds=X_testdata,\n",
    "                  verbosity=3)\n",
    "\n",
    "# When we examine our output directory, we see that now there is a new \"split_outer_0\"\n",
    "# directory, and within that directory reside the individual split directories we have\n",
    "# seen from previous tutorials. There is one split outer directory because there was one\n",
    "# set of left-out data. For this split_outer_0 directory, the Pt host data are left out, and\n",
    "# random 5-fold CV is performed on the remaining data to assess model performance\n",
    "#\n",
    "# How did the model do with predicting the Pt data? My model got an RMSE of 0.282 eV, while\n",
    "# the 5-fold RMSE on the remaining data was 0.153 eV. The prediction of Pt was higher than \n",
    "# this value because random 5-fold CV is an overly optimistic predictor of model performance\n",
    "# when predicting the values of unseen data from a new group!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#\n",
    "# Task 2: Perform nested cross validation to assess model performance on unseen data\n",
    "#\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of just manually specifying which data should be left-out data, we can have MAST-ML\n",
    "# do this automatically via nested cross validation. Any data splitter can be used to perform\n",
    "# nested cross validation. Here, we will perform nested CV with our kernel ridge method using\n",
    "# both 5-fold and leave out group cross validation. Then, we can compare how our previous result\n",
    "# of predicting on Pt compares to the left-out data RMSE values from 5-fold and leave out group\n",
    "# tests. \n",
    "\n",
    "# This time, we are not specifying the leaveout_inds parameter. To use nested CV,\n",
    "# we set nested_CV=True in the evaluate method. The data splitter method is repeated\n",
    "# for each nesting level, so here we are doing 1 cycle of 5-fold CV. That means that there\n",
    "# will be 5 level 1 splits, and 5 level 2 splits for each of the level 1 split, making for \n",
    "# a total of 5*5 = 25 splits. \n",
    "splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=1, n_splits=5)\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  models=[model_krr],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  nested_CV=True,\n",
    "                  verbosity=3)\n",
    "\n",
    "# For leave out group, recall we need to set the groups parameter in the evaluate method.\n",
    "# When doing nested CV with leave out group, the total number of splits will be n_groups*n_groups,\n",
    "# so in our case that is 125 splits (be patient- this run will take about 10 minutes or so).\n",
    "splitter = SklearnDataSplitter(splitter='LeaveOneGroupOut')\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  groups=groups,\n",
    "                  models=[model_krr],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  nested_CV=True,\n",
    "                  verbosity=3)\n",
    "\n",
    "# My previous result of leave out Pt RMSE was 0.282 eV. The nested CV left out data RMSEs are\n",
    "# 0.170 eV for 5-fold and 0.200 eV for leave out group. It's evident that the leave out group\n",
    "# test is more closely aligned with the scale of error one should expect by predicting on a \n",
    "# new group, and the prediction of Pt seems to be a rather difficult one, considering its \n",
    "# error is even higher than the nested leave out group score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#\n",
    "# Task 3: Optimize the hyperparameters of our models to create the best model\n",
    "#\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go back to our dataset from the first task where we leave out Pt and\n",
    "# include hyperparameter optimization for our kernel ridge model. To keep the runs reasonably fast, \n",
    "# we are only going to optimize the alpha parameter in Kernel ridge, which is the regularization strength.\n",
    "# This optimization will be done for each train/test split in the random\n",
    "# 5-fold cross validation stage. Then, the best model will be selected and used to predict the\n",
    "# left out Pt data. \n",
    "\n",
    "# The parameters for hyperparameter optimization routines have a defined structure. The parameter\n",
    "# names need to be separated by semicolons (see below commented part for designating alpha, gamma,\n",
    "# and kernel type). The parameter values are also delimited by semicolons (one set per parameter).\n",
    "# For designating the grid of values to explore, the first number is the lower bound, the second\n",
    "# number is the upper bound, the third number is grid density, and the fourth value is \"lin\" or \n",
    "# \"log\" to denote linear or logarithmic scale, respectively. The final value is the data type of the\n",
    "# parameter.\n",
    "\n",
    "hyperopt = GridSearch(param_names='alpha',\n",
    "                     param_values='-5 5 100 log float',\n",
    "                     scoring='root_mean_squared_error')\n",
    "\n",
    "splitter = SklearnDataSplitter(splitter='RepeatedKFold', n_repeats=1, n_splits=5)\n",
    "splitter.evaluate(X=X,\n",
    "                  y=y, \n",
    "                  models=[model_krr],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  hyperopts=[hyperopt],\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  savepath=savepath,\n",
    "                  X_extra=X_extra,\n",
    "                  leaveout_inds=X_testdata,\n",
    "                  verbosity=3)\n",
    "\n",
    "# Below is an example of optimizing three parameters in the Kernel ridge model. We don't run it here\n",
    "# because it will take a long time\n",
    "# hyperopt = GridSearch(param_names='alpha ; gamma ; kernel',\n",
    "#                     param_values='-5 5 100 log float ; -5 5 100 log float ; linear rbf sigmoid str',\n",
    "#                     scoring='root_mean_squared_error')\n",
    "\n",
    "# How does this model perform on the Pt data compared to the one we ran above? When just using the\n",
    "# non-optimized Kernel ridge model, I got an RMSE of 0.282 eV. After optimizing just the alpha parameter,\n",
    "# the RMSE on the Pt data has dropped to just 0.169 eV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With everything we've covered here, you could combine nested CV with the hyperparameter optimization\n",
    "# to obtain a more realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've now completed your fifth MAST-ML tutorial notebook! Now that you're more familiar with performing detailed\n",
    "# model evaluation with nested cross validation and creating optimized models, it is time to move to one of the final\n",
    "# tutorials in this series, and a subject of great importance when evaluating the efficacy of ML models: predictions\n",
    "# of model errors, domains, and uncertainty quantification (UQ).\n",
    "#\n",
    "# The next example in this notebook series is titled MASTML_Tutorial_6_ErrorAnalysis_UncertaintyQuantification.ipynb, \n",
    "# and will guide you through the process assessing the true and predicted errors of some models on a select dataset\n",
    "# and detail methods to recalibrate the model uncertainty estimates to more accurately reflect the true model errors."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMEVkHt3gXnG4BXBNcr+orE",
   "name": "MASTML_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
