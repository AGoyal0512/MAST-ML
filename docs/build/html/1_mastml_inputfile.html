
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>MAST-ML Input File &#8212; MAterials Simulation Toolkit for Machine Learning (MAST-ML) 2.0 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MAST-ML overview slides" href="2_mastml_overview.html" />
    <link rel="prev" title="Startup" href="0_3_startup.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="2_mastml_overview.html" title="MAST-ML overview slides"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="0_3_startup.html" title="Startup"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MAterials Simulation Toolkit for Machine Learning (MAST-ML) 2.0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="mast-ml-input-file">
<span id="mastml-input-file"></span><h1>MAST-ML Input File<a class="headerlink" href="#mast-ml-input-file" title="Permalink to this headline">¶</a></h1>
<p>This document provides an overview of the various sections and fields of the MAST-ML input file.</p>
<p>A full template input file can be downloaded here: <a class="reference download internal" href="_downloads/MASTML_fullinputfile.conf" download=""><code class="xref download docutils literal"><span class="pre">MASTML_InputFile</span></code></a></p>
<div class="section" id="input-file-sections">
<h2>Input file sections<a class="headerlink" href="#input-file-sections" title="Permalink to this headline">¶</a></h2>
<div class="section" id="general-setup">
<h3>General Setup<a class="headerlink" href="#general-setup" title="Permalink to this headline">¶</a></h3>
<p>The “GeneralSetup” section of the input file allows the user to specify an assortment of basic MAST-ML parameters, ranging
from which column names in the CSV file to use as features for fitting (i.e. X data) or to fit to (i.e. y data), as well
as which metrics to employ in fitting a model, among other things.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">GeneralSetup</span><span class="p">]</span>
    <span class="n">input_features</span> <span class="o">=</span> <span class="n">feature_1</span><span class="p">,</span> <span class="n">feature_2</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span> <span class="ow">or</span> <span class="s2">&quot;Auto&quot;</span>
    <span class="n">target_feature</span> <span class="o">=</span> <span class="n">target_feature</span>
    <span class="n">randomizer</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">root_mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span> <span class="ow">or</span> <span class="s2">&quot;Auto&quot;</span>
    <span class="n">not_input_features</span> <span class="o">=</span> <span class="n">additional_feature_1</span><span class="p">,</span> <span class="n">additional_feature_2</span>
    <span class="n">grouping_feature</span> <span class="o">=</span> <span class="n">grouping_feature_1</span>
    <span class="n">validation_columns</span> <span class="o">=</span> <span class="n">validation_feature_1</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>input_features</strong> List of input X features</li>
<li><strong>target_feature</strong> Target y feature</li>
<li><strong>randomizer</strong> Whether or not to randomize y feature data</li>
<li><strong>metrics</strong> Which metrics to evaluate model fits</li>
<li><strong>not_input_features</strong> Additional features that are not to be fitted on (i.e. not X features)</li>
<li><strong>grouping_feature</strong> Feature names that provide information on data grouping</li>
<li><strong>validation_columns</strong> Feature name that designates whether data will be used for validation (set rows as 1 or 0 in csv file)</li>
</ul>
</div>
<div class="section" id="data-cleaning">
<h3>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this headline">¶</a></h3>
<p>The “DataCleaning” section of the input file allows the user to clean their data to remove rows or columns that contain
empty or NaN fields, or fill in these fields using imputation or principal component analysis methods.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">DataCleaning</span><span class="p">]</span>
    <span class="n">cleaning_method</span> <span class="o">=</span> <span class="n">remove</span><span class="p">,</span> <span class="n">imputation</span><span class="p">,</span> <span class="n">ppca</span>
    <span class="n">imputation_strategy</span> <span class="o">=</span> <span class="n">mean</span><span class="p">,</span> <span class="n">median</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>cleaning_method</strong>  Method of data cleaning. “remove” simply removes columns with missing data. “imputation” uses basic operation to fill in missing values. “ppca” uses principal component analysis to fill in missing values.</li>
<li><strong>imputation_strategy</strong> Only valid field if doing imputation, selects method to impute missing data by using mean, median, etc. of the column</li>
</ul>
</div>
<div class="section" id="clustering">
<h3>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform clustering of data using well-known clustering algorithms available in scikit-learn.
Note that the subsection names must match the corresponding name of the routine in scikit-learn. More information on
clustering routines and the parameters to set for each routine can be found here:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster</a>
For the purpose of this full input file, we use the scikit-learn default parameter values. Note that not all parameters are listed.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">Clustering</span><span class="p">]</span>
    <span class="p">[[</span><span class="n">AffinityPropagation</span><span class="p">]]</span>
        <span class="n">damping</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="n">convergence_iter</span> <span class="o">=</span> <span class="mi">15</span>
        <span class="n">affinity</span> <span class="o">=</span> <span class="n">euclidean</span>
    <span class="p">[[</span><span class="n">AgglomerativeClustering</span><span class="p">]]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">affinity</span> <span class="o">=</span> <span class="n">euclidean</span>
        <span class="n">compute_full_tree</span> <span class="o">=</span> <span class="n">auto</span>
        <span class="n">linkage</span> <span class="o">=</span> <span class="n">ward</span>
    <span class="p">[[</span><span class="n">Birch</span><span class="p">]]</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">branching_factor</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">DBSCAN</span><span class="p">]]</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">min_samples</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">euclidean</span>
        <span class="n">algorithm</span> <span class="o">=</span> <span class="n">auto</span>
        <span class="n">leaf_size</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="p">[[</span><span class="n">KMeans</span><span class="p">]]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">8</span>
        <span class="n">n_init</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">300</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="p">[[</span><span class="n">MiniBatchKMeans</span><span class="p">]]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">8</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="p">[[</span><span class="n">MeanShift</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SpectralClustering</span><span class="p">]]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">8</span>
        <span class="n">n_init</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">affinity</span> <span class="o">=</span> <span class="n">rbf</span>
</pre></div>
</div>
</div>
<div class="section" id="feature-generation">
<h3>Feature Generation<a class="headerlink" href="#feature-generation" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform feature generation based on properties of the constituent elements. These routines were
custom written for MAST-ML, except for PolynomialFeatures. For more information on the MAST-ML custom routines, consult
the MAST-ML online documentation. For more information on PolynomialFeatures, see:
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html</a></p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">FeatureGeneration</span><span class="p">]</span>
    <span class="p">[[</span><span class="n">Magpie</span><span class="p">]]</span>
        <span class="n">composition_feature</span> <span class="o">=</span> <span class="n">Material</span> <span class="n">Compositions</span>
    <span class="p">[[</span><span class="n">MaterialsProject</span><span class="p">]]</span>
        <span class="n">composition_feature</span> <span class="o">=</span> <span class="n">Material</span> <span class="n">Compositions</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="n">my_api_key</span>
    <span class="p">[[</span><span class="n">Citrine</span><span class="p">]]</span>
        <span class="n">composition_feature</span> <span class="o">=</span> <span class="n">Material</span> <span class="n">Compositions</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="n">my_api_key</span>
    <span class="p">[[</span><span class="n">ContainsElement</span><span class="p">]]</span>
        <span class="n">composition_feature</span> <span class="o">=</span> <span class="n">Host</span> <span class="n">element</span>
        <span class="n">all_elements</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">element</span> <span class="o">=</span> <span class="n">Al</span>
        <span class="n">new_name</span> <span class="o">=</span> <span class="n">has_Al</span>
    <span class="p">[[</span><span class="n">PolynomialFeatures</span><span class="p">]]</span>
        <span class="n">degree</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">interaction_only</span><span class="o">=</span><span class="kc">False</span>
        <span class="n">include_bias</span><span class="o">=</span><span class="kc">True</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>composition_feature</strong> Name of column in csv file containing material compositions</li>
<li><strong>api_key</strong> Your API key to access the Materials Project or Citrine. Register for your account at Materials Project: <a class="reference external" href="https://materialsproject.org">https://materialsproject.org</a> or at Citrine: <a class="reference external" href="https://citrination.com">https://citrination.com</a></li>
<li><strong>all_elements</strong> For ContainsElement, whether or not to scan all data rows to assess all elements present in data set</li>
<li><strong>element</strong> For ContainsElement, name of element of interest. Ignored if all_elements = True</li>
<li><strong>new_name</strong> For ContainsElement, name of new feature column to generate. Ignored if all_elements = True</li>
</ul>
</div>
<div class="section" id="feature-normalization">
<h3>Feature Normalization<a class="headerlink" href="#feature-normalization" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform feature normalization of the input or generated features using well-known
feature normalization algorithms available in scikit-learn. Note that the subsection names must match the corresponding
name of the routine in scikit-learn. More information on normalization routines and the parameters to set for each
routine can be found here: <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing</a> .
For the purpose of this full input file, we use the scikit-learn default parameter values. Note that not all parameters are listed,
and only the currently listed normalization routines are supported. In addition, MeanStdevScaler is a custom written normalization
routine for MAST-ML. Additional information on MeanStdevScaler can be found in the online MAST-ML documentation.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">FeatureNormalization</span><span class="p">]</span>
    <span class="p">[[</span><span class="n">Binarizer</span><span class="p">]]</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="p">[[</span><span class="n">MaxAbsScaler</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">MinMaxScaler</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">Normalizer</span><span class="p">]]</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">l2</span>
    <span class="p">[[</span><span class="n">QuantileTransformer</span><span class="p">]]</span>
        <span class="n">n_quantiles</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">output_distribution</span> <span class="o">=</span> <span class="n">uniform</span>
    <span class="p">[[</span><span class="n">RobustScaler</span><span class="p">]]</span>
        <span class="n">with_centering</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">with_scaling</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">[[</span><span class="n">StandardScaler</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">MeanStdevScaler</span><span class="p">]]</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">stdev</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="learning-curve">
<h3>Learning Curve<a class="headerlink" href="#learning-curve" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform learning curve analysis on a dataset. Two types of learning curves will be generated: a
data learning curve (score vs. amount of training data) and a feature learning curve (score vs. number of features).</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">LearningCurve</span><span class="p">]</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">KernelRidge_learn</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedKFold_learn</span>
    <span class="n">scoring</span> <span class="o">=</span> <span class="n">root_mean_squared_error</span>
    <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">selector_name</span> <span class="o">=</span> <span class="n">MASTMLFeatureSelector</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>estimator</strong> A scikit-learn model/estimator. The name needs to match an entry in the [Models] section. Note this model will be removed from the [Models] list after the learning curve is generated.</li>
<li><strong>cv</strong> A scikit-learn cross validation generator. The name needs to match an entry in the [DataSplits] section. Note this method will be removed from the [DataSplits] list after the learning curve is generated.</li>
<li><strong>scoring</strong> A scikit-learn scoring method compatible with MAST-ML. See the MAST-ML online documentation at <a class="reference external" href="https://htmlpreview.github.io/?https://raw.githubusercontent.com/uw-cmg/MAST-ML/dev_Ryan_2018-10-29/docs/build/html/3_metrics.html">https://htmlpreview.github.io/?https://raw.githubusercontent.com/uw-cmg/MAST-ML/dev_Ryan_2018-10-29/docs/build/html/3_metrics.html</a> for more information.</li>
<li><strong>n_features_to_select</strong> The max number of features to use for the feature learning curve.</li>
<li><strong>selector_name</strong> Method to conduct feature selection for the feature learning curve. The name needs to match an entry in the [FeatureSelection] section. Note this method will be removed from the [FeatureSelection] section after the learning curve is generated.</li>
</ul>
</div>
<div class="section" id="feature-selection">
<h3>Feature Selection<a class="headerlink" href="#feature-selection" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform feature selection using routines in scikit-learn, mlxtend and custom-written for MAST-ML.
Note that the subsection names must match the corresponding name of the routine in scikit-learn. More information on
selection routines and the parameters to set for each routine can be found here:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection</a> . For the purpose of this full
input file, we use the scikit-learn default parameter values. Note that not all parameters are listed, and only the
currently listed selection routines are supported. In addition, MASTMLFeatureSelector is a custom written selection
routine for MAST-ML. Additional information on MASTMLFeatureSelector can be found in the online MAST-ML documentation.
Finally, SequentialFeatureSelector is a routine available from the mlxtend package, which documention can be found
here: <a class="reference external" href="http://rasbt.github.io/mlxtend/">http://rasbt.github.io/mlxtend/</a></p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">FeatureSelection</span><span class="p">]</span>
    <span class="p">[[</span><span class="n">GenericUnivariateSelect</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SelectPercentile</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SelectKBest</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SelectFpr</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SelectFdr</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">SelectFwe</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">RFE</span><span class="p">]]</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestRegressor_selectRFE</span>
        <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">SequentialFeatureSelector</span><span class="p">]]</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestRegressor_selectSFS</span>
        <span class="n">k_features</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="p">[[</span><span class="n">RFECV</span><span class="p">]]</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestRegressor_selectRFECV</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut_selectRFECV</span>
        <span class="n">min_features_to_select</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">SelectFromModel</span><span class="p">]]</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">KernelRidge_selectfrommodel</span>
        <span class="n">max_features</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="p">[[</span><span class="n">VarianceThreshold</span><span class="p">]]</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="p">[[</span><span class="n">PCA</span><span class="p">]]</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="p">[[</span><span class="n">MASTMLFeatureSelector</span><span class="p">]]</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">KernelRidge_selectMASTML</span>
        <span class="n">n_features_to_select</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut_selectMASTML</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>estimator</strong>  A scikit-learn model/estimator. The name needs to match an entry in the [Models] section. Note this model will be removed from the [Models] list after the learning curve is generated.</li>
<li><strong>n_features_to_select</strong> The max number of features to select</li>
<li><strong>step</strong> For RFE and RFECV, the number of features to remove in each step</li>
<li><strong>k_features</strong> For SequentialFeatureSelector, the max number of features to select.</li>
<li><strong>cv</strong> A scikit-learn cross validation generator. The name needs to match an entry in the [DataSplits] section. Note this method will be removed from the [DataSplits] list after the learning curve is generated.</li>
</ul>
</div>
<div class="section" id="data-splits">
<h3>Data Splits<a class="headerlink" href="#data-splits" title="Permalink to this headline">¶</a></h3>
<p>Optional section to perform data splits using cross validation routines in scikit-learn, and custom-written for MAST-ML.
Note that the subsection names must match the corresponding name of the routine in scikit-learn. More information on
selection routines and the parameters to set for each routine can be found here:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection</a> . For the purpose of this full
input file, we use the scikit-learn default parameter values. Note that not all parameters are listed, and only the
currently listed data split routines are supported. In addition, NoSplit is a custom written selection routine for
MAST-ML, which simply produces a full data fit with no cross validation. Additional information on NoSplit can be found
in the online MAST-ML documentation.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">DataSplits</span><span class="p">]</span>
    <span class="p">[[</span><span class="n">NoSplit</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">KFold</span><span class="p">]]</span>
        <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">RepeatedKFold</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="c1"># Here, an example of another instance of RepeatedKFold, this one being used in the [LearningCurve] section above.</span>
    <span class="p">[[</span><span class="n">RepeatedKFold_learn</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">GroupKFold</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">LeaveOneOut</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">LeavePOut</span><span class="p">]]</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">RepeatedStratifiedKFold</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">StratifiedKFold</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">ShuffleSplit</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">StratifiedShuffleSplit</span><span class="p">]]</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="p">[[</span><span class="n">LeaveOneGroupOut</span><span class="p">]]</span>
        <span class="c1"># The column name in the input csv file containing the group labels</span>
        <span class="n">grouping_column</span> <span class="o">=</span> <span class="n">Host</span> <span class="n">element</span>
    <span class="c1"># Here, an example of another instance of LeaveOneGroupOut, this one being used in the [FeatureSelection] section above.</span>
    <span class="p">[[</span><span class="n">LeaveOneGroupOut_selectMASTML</span><span class="p">]]</span>
        <span class="c1"># The column name in the input csv file containing the group labels</span>
        <span class="n">grouping_column</span> <span class="o">=</span> <span class="n">Host</span> <span class="n">element</span>
    <span class="c1"># Here, an example of another instance of LeaveOneGroupOut, this one being used based on the creation of the &quot;has_Al&quot;</span>
    <span class="c1"># group from the [[ContainsElement]] routine present in the [FeatureGeneration] section.</span>
    <span class="p">[[</span><span class="n">LeaveOneGroupOut_Al</span><span class="p">]]</span>
        <span class="n">grouping_column</span> <span class="o">=</span> <span class="n">has_Al</span>
    <span class="c1"># Here, an example of another instance of LeaveOneGroupOut, this one being used based on the creation of clusters</span>
    <span class="c1"># from the [[KMeans]] routine present in the [Clustering] section.</span>
    <span class="p">[[</span><span class="n">LeaveOneGroupOut_kmeans</span><span class="p">]]</span>
        <span class="n">grouping_column</span> <span class="o">=</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
<div class="section" id="models">
<h3>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h3>
<p>Optional section to denote different models/estimators for model fitting from scikit-learn. Note that the subsection
names must match the corresponding name of the routine in scikit-learn. More information on different model routines
and the parameters to set for each routine can be found here for ensemble methods:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble</a> and here for kernel ridge and linear methods:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.kernel_ridge">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.kernel_ridge</a> and here for neural network methods:
<a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.neural_network">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.neural_network</a> and here for support vector machine
and decision tree methods: <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm</a> . For the purpose of
this full input file, we use the scikit-learn default parameter values. Note that not all parameters are listed, and only
the currently listed data split routines are supported.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">Models</span><span class="p">]</span>
    <span class="c1"># Ensemble methods</span>

    <span class="p">[[</span><span class="n">AdaBoostClassifier</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">AdaBoostRegressor</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">BaggingClassifier</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">max_features</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">BaggingRegressor</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">max_features</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">ExtraTreesClassifier</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">gini</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">ExtraTreesRegressor</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">mse</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">GradientBoostingClassifier</span><span class="p">]]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">deviance</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">subsample</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">friedman_mse</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">GradientBoostingRegressor</span><span class="p">]]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">ls</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">subsample</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">friedman_mse</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">RandomForestClassifier</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">gini</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="p">[[</span><span class="n">RandomForestRegressor</span><span class="p">]]</span>
        <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">mse</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># Kernel ridge and linear methods</span>

    <span class="p">[[</span><span class="n">KernelRidge</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">linear</span>
    <span class="c1"># Here, an example of another instance of KernelRidge, this one being used based by the [[MASTMLFeatureSelector]]</span>
    <span class="c1"># method from the [FeatureSelection] section.</span>
    <span class="p">[[</span><span class="n">KernelRidge_selectMASTML</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">linear</span>
    <span class="c1"># Here, an example of another instance of KernelRidge, this one being used based in the [LearningCurve] section.</span>
    <span class="p">[[</span><span class="n">KernelRidge_learn</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">linear</span>

    <span class="p">[[</span><span class="n">ARDRegression</span><span class="p">]]</span>
        <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="p">[[</span><span class="n">BayesianRidge</span><span class="p">]]</span>
        <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="p">[[</span><span class="n">ElasticNet</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">HuberRegressor</span><span class="p">]]</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1.35</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="p">[[</span><span class="n">Lars</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">Lasso</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">LassoLars</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="p">[[</span><span class="n">LassoLarsIC</span><span class="p">]]</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">aic</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="p">[[</span><span class="n">LinearRegression</span><span class="p">]]</span>
    <span class="p">[[</span><span class="n">LogisticRegression</span><span class="p">]]</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">Perceptron</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="p">[[</span><span class="n">Ridge</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">RidgeClassifier</span><span class="p">]]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">SGDClassifier</span><span class="p">]]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">hinge</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="p">[[</span><span class="n">SGDRegressor</span><span class="p">]]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">squared_loss</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>

    <span class="c1"># Neural networks</span>

    <span class="p">[[</span><span class="n">MLPClassifier</span><span class="p">]]</span>
        <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">relu</span>
        <span class="n">solver</span> <span class="o">=</span> <span class="n">adam</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">auto</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">constant</span>
    <span class="p">[[</span><span class="n">MLPRegressor</span><span class="p">]]</span>
        <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">relu</span>
        <span class="n">solver</span> <span class="o">=</span> <span class="n">adam</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">auto</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">constant</span>

    <span class="c1"># Support vector machine methods</span>

    <span class="p">[[</span><span class="n">LinearSVC</span><span class="p">]]</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">squared_hinge</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.0001</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">LinearSVR</span><span class="p">]]</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">epsilon_insensitive</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.0001</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">[[</span><span class="n">NuSVC</span><span class="p">]]</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">rbf</span>
        <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">NuSVR</span><span class="p">]]</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">rbf</span>
        <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">SVC</span><span class="p">]]</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">rbf</span>
        <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">[[</span><span class="n">SVR</span><span class="p">]]</span>
        <span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">rbf</span>
        <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="c1"># Decision tree methods</span>

    <span class="p">[[</span><span class="n">DecisionTreeClassifier</span><span class="p">]]</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">gini</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">best</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">DecisionTreeRegressor</span><span class="p">]]</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">mse</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">best</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">ExtraTreeClassifier</span><span class="p">]]</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">gini</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">random</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">[[</span><span class="n">ExtraTreeRegressor</span><span class="p">]]</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">mse</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">random</span>
        <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="plot-settings">
<h3>Plot Settings<a class="headerlink" href="#plot-settings" title="Permalink to this headline">¶</a></h3>
<p>This section controls which types of plots MAST-ML will write to the results directory.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">PlotSettings</span><span class="p">]</span>
    <span class="n">target_histogram</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">train_test_plots</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">predicted_vs_true</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">predicted_vs_true_bars</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">best_worst_per_point</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">feature_vs_target</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">average_normalized_errors</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>target_histogram</strong> Whether or not to output target data histograms</li>
<li><strong>train_test_plots</strong> Whether or not to output parity plots within each CV split</li>
<li><strong>predicted_vs_true</strong> Whether or not to output summarized parity plots</li>
<li><strong>predicted_vs_true_bars</strong> Whether or not to output averaged parity plots</li>
<li><strong>best_worst_per_point</strong> Whether or not to output parity plot showing best and worst split per point</li>
<li><strong>feature_vs_target</strong> Whether or not to show plots of target feature as a function of each individual input feature</li>
<li><strong>average_normalized_errors</strong> Whether or not to show the average plots of the normalized errors</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="2_mastml_overview.html" title="MAST-ML overview slides"
             >next</a> |</li>
        <li class="right" >
          <a href="0_3_startup.html" title="Startup"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">MAterials Simulation Toolkit for Machine Learning (MAST-ML) 2.0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, University of Wisconsin-Madison Computational Materials Group.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>