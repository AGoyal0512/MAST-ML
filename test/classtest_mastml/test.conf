[General Setup]

    save_path = ./
    input_features = time, N_sine_feature,N_linear_feature
    target_feature = y_feature
    target_error_feature = N_linear_feature #need to change
    labeling_features = str_cat, num_id
    grouping_feature = str_cat

[Data Setup]

    [[Initial]]
    data_path = ../random_data/random_test_data.csv
    weights = False #haven't tested weighting; may move

    [[Extrapolation]]
    data_path = ../random_data/random_test_data_noy.csv
    weights = False
    
    [[ExtrapolationNoD]]
    data_path = ../random_data/random_test_data_noy_noD.csv
    weights = False

    [[InitialNoD]]
    data_path = ../random_data/random_test_data_noD.csv
    weights = False
    
    [[InitialNoA]]
    data_path = ../random_data/random_test_data_noA.csv
    weights = False

    [[Set2]]
    data_path = ../random_data/random_set2_data.csv
    weights = False


[Models and Tests to Run]

    models = gkrr_model
    #Okay tests:
    #test_cases = SingleFit_withfilter,SingleFit_withy,SingleFit_noy
    #test_cases = SingleFitGrouped_test,SingleFitGrouped_match,SingleFitGrouped_nomatch,SingleFitGrouped_withfilter
    #test_cases = SingleFitPerGroup_test
    #test_cases = PredictionVsFeature_test
    #Okay tests, all:
    #test_cases = SingleFit_withfilter,SingleFit_withy,SingleFit_noy,SingleFitGrouped_test,SingleFitGrouped_match,SingleFitGrouped_nomatch,SingleFitGrouped_withfilter,SingleFitPerGroup_test,PredictionVsFeature_test
    
    #Under development:
    test_cases = LeaveOutPercentCV_50, KFoldCV_5fold
    #test_cases = LeaveOutPercentCV_50, LeaveOneOutCV, LeaveOutGroupCV_cat
    #test_cases = KFoldCV_5fold, LeaveOutPercentCV_50, LeaveOneOutCV, LeaveOutGroupCV_cat
    #test_cases = ParamOptGA

[Test Parameters]

    [[SingleFit_withy]]
    training_dataset = Initial
    testing_dataset  = Initial
    xlabel = Measured target
    ylabel = Target prediction
    stepsize = 1.0
    
    [[SingleFit_withfilter]]
    training_dataset = Initial
    testing_dataset  = Initial
    xlabel = Measured target
    ylabel = Target prediction
    stepsize = 1.0
    plot_filter_out = time;>;7.8,time;<;1.3,str_cat;=;A

    [[SingleFit_noy]]
    training_dataset = Initial
    testing_dataset = Extrapolation

    [[SingleFitGrouped_test]]
    training_dataset=Initial
    testing_dataset=Initial
    xlabel=Initial dataset measured
    ylabel=Initial dataset predicted
    stepsize=0.5
    mark_outlying_groups = 2
    fit_only_on_matched_groups = 0
    
    [[SingleFitGrouped_withfilter]]
    training_dataset=Initial
    testing_dataset=Initial
    xlabel=Initial dataset measured
    ylabel=Initial dataset predicted
    stepsize=0.5
    mark_outlying_groups = 2
    fit_only_on_matched_groups = 0
    plot_filter_out = str_cat;=;C,time;>;8.0
    
    [[SingleFitGrouped_nomatch]]
    training_dataset=Initial
    testing_dataset=InitialNoD
    xlabel=Initial dataset measured
    ylabel=Initial dataset predicted
    stepsize=0.5
    mark_outlying_groups = 2
    fit_only_on_matched_groups = 0
    
    [[SingleFitGrouped_match]]
    training_dataset=Initial
    testing_dataset=InitialNoD
    xlabel=Initial dataset measured
    ylabel=Initial dataset predicted
    stepsize=0.5
    mark_outlying_groups = 2
    fit_only_on_matched_groups = 1
    
    [[SingleFitPerGroup_test]]
    training_dataset=InitialNoA
    testing_dataset=InitialNoD
    xlabel=Initial dataset measured
    ylabel=Initial dataset predicted
    stepsize=0.5
    mark_outlying_groups = 2
    plot_filter_out = time;>;7.5

    [[PredictionVsFeature_test]]
    training_dataset=Initial
    testing_dataset=Initial, Set2,Extrapolation
    input_features=time, N_sine_feature, N_linear_feature
    labeling_features=str_cat, num_id
    xlabel=Initial dataset measured
    ylabel=Predicted
    stepsize=0.5
    grouping_feature = str_cat
    mark_outlying_groups = 2
    feature_plot_xlabel = Time
    feature_plot_ylabel = Y feature
    feature_plot_feature = time
    plot_filter_out = time;>;4.2
    fit_only_on_matched_groups = 0
    markers = x,s,^,+,o,d
    outlines = blue, red, black, magenta, green, cyan
    linestyles = -, None, :, None, --, -
    data_labels = Initial repredict, Set2, Extrapolation test
    sizes = 10,4,12,6,8,2
    legendloc = lower right

    [[KFoldCV_5fold]]
    training_dataset = Initial
    testing_dataset  = Initial
    xlabel = Measured target
    ylabel = Target prediction
    stepsize = 1.0
    num_folds = 5
    num_cvtests = 20
    fix_random_for_testing = 1
    mark_outlying_points = 1,3

    [[LeaveOutPercentCV_50]]
    training_dataset = Initial
    testing_dataset  = Initial
    xlabel = Measured target
    ylabel = Target prediction
    stepsize = 1.0
    mark_outlying_points = 1,3
    percent_leave_out = 50
    num_cvtests = 20
    fix_random_for_testing = 1
    
    [[LeaveOutGroupCV_cat]]
    training_dataset = Initial
    testing_dataset  = Initial
    input_features=time, N_sine_feature, N_linear_feature
    labeling_features = str_cat
    target_feature=y_feature
    target_error_feature=N_linear_feature
    xlabel = Group
    ylabel = RMSE (arb. units)
    mark_outlying_points = 3
    grouping_feature = str_cat
    
    [[LeaveOneOutCV]]
    training_dataset = Initial
    testing_dataset  = Initial
    input_features=time, N_sine_feature, N_linear_feature
    labeling_features = str_cat
    target_feature=y_feature
    target_error_feature=N_linear_feature
    xlabel = Measured
    ylabel = Predicted
    stepsize = 1.0
    mark_outlying_points = 3

    [[ParamOptGA]]
    training_dataset = Initial
    testing_dataset = Initial
    num_folds = 2  #todo: also allow percent_leave_out = 50 for example
    num_cvtests = 20
    population_size = 5
    convergence_generations = 3
    max_generations = 10
    fix_random_for_testing = 1
    num_parents = 2
    use_multiprocessing = 1
    additional_feature_methods = testing_subtraction;col1:N_sine_feature;col2:N_linear_feature
    #additional_feature_methods = calculate_EffectiveFluence;flux_feature:N_sine_feature;fluence_feature:N_linear_feature


[Model Parameters]

    [[linear_model]]
    fit_intercept = True

    [[decision_tree_model]]
    max_depth = 5
    min_samples_split = 2
    min_samples_leaf = 1
    split_criterion = mse

    [[gkrr_model]]
    alpha = 0.00139
    coef0 = 1
    degree = 3
    gamma = 0.518
    kernel = rbf

    [[lkrr_model]]
    alpha = 0.00518
    gamma = 0.518
    kernel = laplacian

    [[randomforest_model]]
    split_criterion = mse
    estimators = 100
    max_depth = 5
    min_samples_split = 2
    min_samples_leaf = 1
    max_leaf_nodes = 2
    jobs = 1

    [[adaboost_model]]
    estimators = 275
    max_depth = 12
    min_samples_split = 2
    min_samples_leaf = 1
    learning rate = 1
    loss function = linear

    #minmax, size, transfer_function are the verbatim arguments for neurolab.net.newff()
    #training_algorithm is the verbatim 'support train fcn' for neurolab.train omitting 'train_'
    #see: https://pythonhosted.org/neurolab/lib.html#module-neurolab.net
    #epochs,show,goal are neurolab.net.train() arguments
    #see: https://pythonhosted.org/neurolab/lib.html#train-algorithms-based-gradients-algorithms
    #NOTE: minmax is verbose b/c [[0,1]]*9 will have bad pointers
    [[nn_model_neurolab]]
    #minmax = [[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]]
    minmax = [0, 1], [0, 1], [0, 1]
    size = 11, 1
    transfer_function = TanSig
    training_algorithm = bfgs
    epochs = 5
    show = False
    goal = 0.01[default]
