{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matminer is an optional dependency. To install matminer, do pip install matminer\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from mastml.mastml import Mastml\n",
    "from mastml.feature_generators import ElementalFeatureGenerator, ElementalFractionGenerator\n",
    "# from mastml.feature_generators import ElementalFeatureGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pfile_X = \"Codes/bandgap_pbe_X.pickle\"\n",
    "pfile_Y = \"Codes/bandgap_pbe_Y.pickle\"\n",
    "\n",
    "with open(pfile_X, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num compositions 74992\n"
     ]
    }
   ],
   "source": [
    "# for k,v in data.items():\n",
    "    # print(k)\n",
    "\n",
    "# n = 74992\n",
    "# acc = 0\n",
    "# for id in data['icsd_id']:\n",
    "#     if not id:\n",
    "#         acc += 1\n",
    "# print(data)\n",
    "# print(acc / n)\n",
    "# print(list(numpy.unique(data['reference'])))\n",
    "# print(list(numpy.unique(data['comments'])))\n",
    "# print(list(numpy.unique(data['bandgap type'])))\n",
    "# print(list(numpy.unique(data['comp method'])))\n",
    "\n",
    "x_clean = data[['composition', 'structure', 'space group']]\n",
    "# print(\"x_clean\", x_clean)\n",
    "\n",
    "composition = x_clean['composition']\n",
    "structure = x_clean['structure']\n",
    "\n",
    "m = float(\"inf\")\n",
    "\n",
    "# foo = structure[m]\n",
    "# compositions = [composition[i] for i in range(m)]\n",
    "compositions = [comp for i, comp in enumerate(composition) if i < m]\n",
    "\n",
    "# sites = foo['sites']\n",
    "# print(\"compositions\", compositions)\n",
    "print(\"num compositions\", len(compositions))\n",
    "\n",
    "# l = []\n",
    "# for s in sites:\n",
    "#     l.append(s['species'])\n",
    "\n",
    "# element_names = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K',\n",
    "#                  'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb',\n",
    "#                  'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs',\n",
    "#                  'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta',\n",
    "#                  'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa',\n",
    "#                  'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt',\n",
    "#                  'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og']\n",
    "\n",
    "# print(bar)\n",
    "# decomposeComposition(bar)\n",
    "# print(bar)\n",
    "# EnsembleModelFeatureSelector()\n",
    "# generate_elementfraction_features(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector shape (74992, 118) y None\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame([compositions])\n",
    "df = pd.DataFrame(compositions)\n",
    "# print(\"df\", df)\n",
    "# ! USE ElementFraction instead ElementalFractionGenerator\n",
    "# e = ElementalFeatureGenerator(df)\n",
    "e = ElementalFractionGenerator(df)\n",
    "e.fit()\n",
    "x, y = e.transform()\n",
    "print(\"vector shape\", x.shape, \"y\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping for O\n",
      "\ttheshold:\t0\n",
      "\tpercent in O_group:\t0.4545018135267762\n",
      "\t\tdist O_centroid not_O_centroid\t0.54322672127658\n",
      "\t\tdist O_centroid x_centroid\t0.29632919130016977\n",
      "\t\tdist not_O_centroid x_centroid\t0.24689752997641023\n",
      "Grouping for B\n",
      "\ttheshold:\t0\n",
      "\tpercent in B_group:\t0.04636494559419672\n",
      "\t\tdist B_centroid not_B_centroid\t0.2953864981862926\n",
      "\t\tdist B_centroid x_centroid\t0.2816909192686254\n",
      "\t\tdist not_B_centroid x_centroid\t0.013695578917667163\n",
      "Grouping for F\n",
      "\ttheshold:\t0\n",
      "\tpercent in F_group:\t0.0855824621292938\n",
      "\t\tdist F_centroid not_F_centroid\t0.5070204229979047\n",
      "\t\tdist F_centroid x_centroid\t0.46362836684790687\n",
      "\t\tdist not_F_centroid x_centroid\t0.0433920561499979\n",
      "Grouping for Cl\n",
      "\ttheshold:\t0\n",
      "\tpercent in Cl_group:\t0.04140441647109025\n",
      "\t\tdist Cl_centroid not_Cl_centroid\t0.40092635377725583\n",
      "\t\tdist Cl_centroid x_centroid\t0.3843262320512259\n",
      "\t\tdist not_Cl_centroid x_centroid\t0.016600121726030037\n",
      "Grouping for Br\n",
      "\ttheshold:\t0\n",
      "\tpercent in Br_group:\t0.019255387241305738\n",
      "\t\tdist Br_centroid not_Br_centroid\t0.4306529993168135\n",
      "\t\tdist Br_centroid x_centroid\t0.4223606090483381\n",
      "\t\tdist not_Br_centroid x_centroid\t0.008292390268475395\n",
      "Grouping for I\n",
      "\ttheshold:\t0\n",
      "\tpercent in I_group:\t0.02126893535310433\n",
      "\t\tdist I_centroid not_I_centroid\t0.43950933602712594\n",
      "\t\tdist I_centroid x_centroid\t0.4301614403720788\n",
      "\t\tdist not_I_centroid x_centroid\t0.009347895655047116\n"
     ]
    }
   ],
   "source": [
    "# list(x.items())\n",
    "# print(*x.items(), sep=\"\\n\")\n",
    "# print(x.iloc[0])\n",
    "\n",
    "## verify rows sum to 1\n",
    "# total = x.sum(axis=1, numeric_only= True)\n",
    "# print(\"total\", total)\n",
    "\n",
    "material_group_char = [\"O\", \"B\", \"F\", \"Cl\", \"Br\", \"I\"]\n",
    "for mat in material_group_char:\n",
    "    print(\"Grouping for\", mat)\n",
    "    st1 = 100\n",
    "    st2 = 10\n",
    "    # thresholds = [i/st1 for i in range(0,st1)] + [i/st2 for i in range(1,st2)]\n",
    "    thresholds = [0]\n",
    "    for th in thresholds:\n",
    "        # print(\"threshold\", th)\n",
    "        O_group = x[x[mat] > th]\n",
    "        not_O_group = x[x[mat] <= th]\n",
    "        # print(\"o group shape for theshold\", th, O_group.shape, O_group.shape[0]/x.shape[0])\n",
    "        perc_in_group = O_group.shape[0]/x.shape[0]\n",
    "        print(f\"\\ttheshold:\\t{th}\\n\\tpercent in {mat}_group:\\t{perc_in_group}\")\n",
    "        if perc_in_group == 0:\n",
    "            continue\n",
    "        # print(\"not o group shape for theshold\", th, not_O_group.shape, not_O_group.shape[0]/x.shape[0])\n",
    "\n",
    "        # th = 0.5\n",
    "        O_group = x[x[mat] > th]\n",
    "        not_O_group = x[x[mat] <= th]\n",
    "\n",
    "        o_centroid = O_group.mean(axis=0)\n",
    "        not_o_centroid = not_O_group.mean(axis=0)\n",
    "        x_cent = x.mean(axis=0)\n",
    "\n",
    "        # groups = (o_centroid, not_o_centroid, x_cent)\n",
    "        # group_names = (\"o_centroid\", \"not_o_centroid\", \"x_cent\")\n",
    "        groups = {f\"{mat}_centroid\": o_centroid, f\"not_{mat}_centroid\": not_o_centroid, \"x_centroid\": x_cent}\n",
    "\n",
    "        pairs = list(itertools.combinations(list(groups.items()), 2))\n",
    "        # print(*pairs, sep=\"\\n\")\n",
    "\n",
    "        distances = []\n",
    "        for ((g1_name, g1), (g2_name, g2)) in pairs:\n",
    "            dist = np.sqrt(np.sum([(a-b)*(a-b) for a, b in zip(g1, g2)]))\n",
    "            distances.append(((g1_name, g2_name), dist))\n",
    "        for (n1, n2), d in distances:\n",
    "            print(f\"\\t\\tdist {n1} {n2}\\t{d}\")\n",
    "\n",
    "    # print(\"o_centroid\", o_centroid)\n",
    "    # print(\"not_o_centroid\", not_o_centroid)\n",
    "    # print(\"x_cent\", x_cent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute distances"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb9a3b69315989b71ebfa9a6e5d99cd0b47220ba2e2aefc36423c82f8837c3dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
