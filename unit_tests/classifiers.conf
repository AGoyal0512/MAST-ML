
[General Setup]
    save_path = ./results/classifiers
    input_features = x_coord, y_coord
    target_feature = cluster_num
    grouping_feature = None
    labeling_features = None

[Data Setup]
    [[Initial]]
        data_path = ./classification_data.csv

[Feature Normalization]
    normalize_x_features = False
    normalize_y_feature = False
    feature_normalization_type = standardize
    feature_scale_min = 0
    feature_scale_max = 1

[Feature Generation]
    perform_feature_generation = False
    add_magpie_features = True
    add_materialsproject_features = False
    materialsproject_apikey = 'TtAHFCrZhQa7cwEy' # Use your own Materials Project API key
    add_citrine_features = False
    citrine_apikey = 'amQVQutFrr7etr4ufQQh0gtt' # Use your own Citrine API key

[Feature Selection]
    perform_feature_selection = False
    remove_constant_features = True
    feature_selection_algorithm = univariate_feature_selection
    # also try: sequential_forward_selection
    #           recursive_feature_elimination
    use_mutual_information = False
    number_of_features_to_keep = 10
    scoring_metric = r2_score
    generate_feature_learning_curve = False
    model_to_use_for_learning_curve = gkrr_model_regressor

[Models and Tests to Run]
    models = k_nearest_neighbors_classifier, support_vector_machine_model_classifier, decision_tree_model_classifier, random_forest_model_classifier, extra_trees_model_classifier
    test_cases = SingleFit

[Test Parameters]

    [[SingleFit]]
        training_dataset = Initial
        testing_dataset  = Initial
        xlabel = input features
        ylabel = predicted class
        plot_filter_out = None

[Model Parameters]

    [[gkrr_model_regressor]]
        alpha = 0.003019951720
        gamma = 3.467368504525
        coef0 = 1
        degree = 3
        kernel = rbf

    [[k_nearest_neighbors_classifier]]

    [[support_vector_machine_model_classifier]]
        C = 1
        kernel = rbf # Choose between linear, rbf, logistic
        degree = 3
        gamma = 0.05
        coef0 = 1

    [[decision_tree_model_classifier]]
        criterion = entropy # Choose between gini, entropy
        splitter = best
        max_depth = 22
        min_samples_split = 2
        min_samples_leaf = 1

    [[random_forest_model_classifier]]
        criterion = entropy # Choose between gini, entropy
        n_estimators = 100
        max_depth = 5
        min_samples_split = 2
        min_samples_leaf = 1
        max_leaf_nodes = 2

    [[extra_trees_model_classifier]]
        criterion = entropy # Choose between gini, entropy
        n_estimators = 100
        max_depth = 5
        min_samples_split = 2
        min_samples_leaf = 1
        max_leaf_nodes = 2
