
[General Setup]
    save_path = ./results/example_classifier
    input_features = x_coord, y_coord
    target_feature = cluster_num
    grouping_feature = None
    labeling_features = None

[Data Setup]
    [[Initial]]
        data_path = ./classification_data.csv

[Feature Normalization]
    normalize_x_features = False
    normalize_y_feature = False
    feature_normalization_type = standardize
    feature_scale_min = 0
    feature_scale_max = 1

[Feature Generation]
    perform_feature_generation = False
    add_magpie_features = True
    add_materialsproject_features = False
    materialsproject_apikey = 'TtAHFCrZhQa7cwEy' # Use your own Materials Project API key
    add_citrine_features = False
    citrine_apikey = 'amQVQutFrr7etr4ufQQh0gtt' # Use your own Citrine API key

[Feature Selection]
    perform_feature_selection = False
    remove_constant_features = True
    feature_selection_algorithm = univariate_feature_selection
    # also try: sequential_forward_selection
    #           recursive_feature_elimination
    use_mutual_information = False
    number_of_features_to_keep = 10
    scoring_metric = r2_score
    generate_feature_learning_curve = False
    model_to_use_for_learning_curve = gkrr_model_regressor

[Models and Tests to Run]
    models = k_nearest_neighbors_classifier
    test_cases = SingleFit

[Test Parameters]

    [[SingleFit]]
        training_dataset = Initial
        testing_dataset  = Initial
        xlabel = input features
        ylabel = predicted class
        plot_filter_out = None

[Model Parameters]

    [[gkrr_model_regressor]]
        alpha = 0.003019951720
        gamma = 3.467368504525
        coef0 = 1
        degree = 3
        kernel = rbf

    [[k_nearest_neighbors_classifier]]
        foo = 10 #fake parameter for experimenting
