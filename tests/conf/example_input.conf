# You run this with
# python3 -m mastml.mastml_driver tests/conf/example_input.conf tests/csv/example_data.csv -o results/mastml_tutorial

[GeneralSetup]
    input_features = Auto
    target_feature = Reduced barrier (eV)
    randomizer = False
    metrics = Auto
    not_input_features = Host element, Solute element, predict_Pt
    grouping_feature = Host element
    validation_columns = predict_Pt

#[DataCleaning]
#    cleaning_method = imputation
#    imputation_strategy = mean

#[FeatureGeneration]
#    [[Magpie]]
#        composition_feature = Solute element

[FeatureNormalization]
    [[StandardScaler]]

#[FeatureSelection]
#    [[SequentialFeatureSelector]]
#        estimator = KernelRidge_select
#        k_features = 20

#[LearningCurve]
#    estimator = KernelRidge_learn
#    cv = RepeatedKFold_learn
#    scoring = root_mean_squared_error
#    n_features_to_select = 20
#    selector_name = SelectKBest

[Models]
    [[KernelRidge]]
        kernel = rbf
        alpha = 0.034
        gamma = 0.138
    #[[KernelRidge_select]]
    #    kernel = rbf
    #    alpha = 1
    #    gamma = 1
    #[[KernelRidge_learn]]
    #    kernel = rbf
    #    alpha = 1
    #    gamma = 1
    #[[ModelImport]]
    #    model_path = models/KernelRidge_split_12.pkl

[DataSplits]
    #[[NoSplit]]
    [[RepeatedKFold]]
        n_splits = 5
        n_repeats = 2
    #[[RepeatedKFold_learn]]
    #    n_splits = 5
    #    n_repeats = 2
    [[LeaveOneGroupOut]]
        grouping_column = Host element

#[HyperOpt]
#    [[GridSearch]]
#        estimator = KernelRidge
#        cv = RepeatedKFold
#        param_names = alpha ; gamma
#        param_values = -5 5 100 log ; -5 5 100 log
#        scoring = root_mean_squared_error